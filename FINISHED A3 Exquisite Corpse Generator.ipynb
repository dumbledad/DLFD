{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import Helpers\n",
    "import numpy as np\n",
    "import codecs\n",
    "\n",
    "helper = Helpers.Exquisite_Corpse\n",
    "\n",
    "encoder = spacy.load('en')\n",
    "\n",
    "with open('data/final_lexicon.pkl', 'rb') as f:\n",
    "    lexicon = pickle.load(f)\n",
    "\n",
    "lexicon_lookup = helper.get_lexicon_lookup(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU\n",
    "\n",
    "def create_model(seq_input_len, n_input_nodes, n_embedding_nodes, n_hidden_nodes, stateful=False, batch_size=None):\n",
    "\n",
    "    input_layer = Input(batch_shape=(batch_size, seq_input_len), name='input_layer')\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=n_input_nodes,\n",
    "                               output_dim=n_embedding_nodes,\n",
    "                               mask_zero=True, name='embedding_layer')(input_layer)\n",
    "    \n",
    "    gru_layer1 = GRU(n_hidden_nodes,\n",
    "                    return_sequences=True,\n",
    "                    stateful=stateful,\n",
    "                    name='hidden_layer1')(embedding_layer)\n",
    "    \n",
    "    gru_layer2 = GRU(n_hidden_nodes,\n",
    "                    return_sequences=True,\n",
    "                    stateful=stateful,\n",
    "                    name='hidden_layer2')(gru_layer1)\n",
    "    \n",
    "    output_layer = TimeDistributed(Dense(n_input_nodes, activation=\"softmax\"),\n",
    "                                  name='output_layer')(gru_layer2)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_model = create_model(seq_input_len=1,\n",
    "                              n_input_nodes=len(lexicon) + 1,\n",
    "                              n_embedding_nodes=250,\n",
    "                              n_hidden_nodes = 400,\n",
    "                              stateful=True,\n",
    "                              batch_size=1)\n",
    "\n",
    "predictor_model.load_weights('corpse_weights50.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in',\n",
       "  'the',\n",
       "  'morning',\n",
       "  ',',\n",
       "  'i',\n",
       "  'travelled',\n",
       "  'to',\n",
       "  'a',\n",
       "  'distant',\n",
       "  'land',\n",
       "  'where',\n",
       "  'the',\n",
       "  'creature',\n",
       "  'and',\n",
       "  'my',\n",
       "  'sister',\n",
       "  'were',\n",
       "  'hiding',\n",
       "  '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_line = \"In the morning, I travelled to a distant land where the creature and my sister were hiding.\"\n",
    "\n",
    "words = [ [word.lower_ for word in encoder(test_line)] ]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1929,\n",
       "  1896,\n",
       "  221,\n",
       "  1330,\n",
       "  868,\n",
       "  4084,\n",
       "  3700,\n",
       "  873,\n",
       "  381,\n",
       "  790,\n",
       "  1412,\n",
       "  1896,\n",
       "  3760,\n",
       "  4070,\n",
       "  2921,\n",
       "  547,\n",
       "  3124,\n",
       "  568,\n",
       "  262]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = helper.tokens_to_ids(words, lexicon)\n",
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', and the wretch , was so been that the fire , and declined the society mingling of concern .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = helper.generate_response(predictor_model, lexicon_lookup, model_input[0])\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
